


# Import pandas using the standard alias
import pandas as pd


# Import the file and print the first 5 rows
df = pd.read_csv('Data/Zipcode_Demos.csv', index_col = 0)
df.head()


# Print the last 5 rows of df
df.tail(5)


# What is going on with this data set? Anything unusual?
# df is really two table views, one on top of the other. 
# > The first is a summary view of the raw data below. 
# > There is also a blank row at row 1 in the file.


# Clean up the dataset
prev_count = 10**3
for row in range(len(df)):  # Use positional index
    count = 0
    for entry in df.iloc[row].isnull():
        if entry:
            count += 1
    if count != prev_count and row != 0:
        print(f'On row {row} there are {count} null values. The previous row had {prev_count} null values.')
    prev_count = count


# importing the first part of the data
df1 = pd.read_csv('Data/Zipcode_Demos.csv', skiprows=[1], nrows=45, usecols=[0, 1, 2]
                  #, index_col = 0
                 )
df1.head()


# how about the last parts , last 5 rows
df1.tail()


# now, lets import the second part of the data part
df2 = pd.read_csv('Data/Zipcode_Demos.csv', skiprows=47)
df2.head()





# Hint: Here's a useful programming pattern to use
try:
    df = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv')
except Exception as e:
    print(e)


# # Iteration 1 
for i in range(1500, 2000):
    try:
        df = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv', nrows = i)
    except:
        print(f'First failure at: {i}')
        break
df1 = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv', nrows = i-1)
print(len(df))
df1.head()


# checking 
df1.tail()


# checking the second iteration
# Iteration 2 
for i in range(0,500):
    try:
        temp = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv', 
                           skiprows=1962, 
                           nrows = i,
                           names = df1.columns)
    except:
        print(f'First failure at: {i}')
        break
df2 = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv', 
                  skiprows = 1962,
                  nrows = i-1,
                  names = df1.columns)
print(len(df2))
df2.head()


temp = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv', 
                   names = df1.columns,
                   skiprows = 1)

print(len(temp))
temp.head()


# brian
# Solving the above error:
    # >>> ParserError: Error tokenizing data. C error: Expected 10 fields in line 2331, saw 11
# (i) Inspect the Problematic Row
with open('Data/Yelp_Reviews_Corrupt.csv', 'r') as file:
    lines = file.readlines()
    print(lines[2330:2333])  # Rows 2331 and its surrounding lines





# brian
# Solving the above error:
    # >>> ParserError: Error tokenizing data. C error: Expected 10 fields in line 2331, saw 11
# (ii) Skip the Problematic Row
temp = pd.read_csv(
    'Data/Yelp_Reviews_Corrupt.csv',
    names=df1.columns,
    skiprows=1,
    on_bad_lines='skip'  # Skip problematic rows
)
print(len(temp))
temp.head()


# brian
import csv
# Solving the above error:
    # >>> ParserError: Error tokenizing data. C error: Expected 10 fields in line 2331, saw 11
# (iii) Handle Quoting Issues
temp = pd.read_csv(
    'Data/Yelp_Reviews_Corrupt.csv',
    names=df1.columns,
    skiprows=1,
    quoting=csv.QUOTE_MINIMAL  # Handle quoting issues
)
print(len(temp))
temp.head() # this presents the same error


# brian
# Solving the above error:
    # >>> ParserError: Error tokenizing data. C error: Expected 10 fields in line 2331, saw 11
# (iv) Diagnose and Debug
chunksize = 1000
for chunk in pd.read_csv('Data/Yelp_Reviews_Corrupt.csv', names=df1.columns, skiprows=1, chunksize=chunksize):
    print(chunk.shape)  # Check the size of each chunk


# brian
# Solving the above error:
    # >>> ParserError: Error tokenizing data. C error: Expected 10 fields in line 2331, saw 11
# (V) Clean the File Before Loading\
# Correct misaligned rows by enforcing consistent column counts
with open('Data/Yelp_Reviews_Corrupt.csv', 'r') as infile, open('Data/Cleaned_Yelp_Reviews.csv', 'w') as outfile:
    for line in infile:
        if line.count(',') == 9:  # Assuming 10 fields and 9 commas
            outfile.write(line)


# finally continuing
pd.read_csv('Data/Yelp_Reviews_Corrupt.csv', 
            skiprows = len(df1) + len(df2), 
            names=df1.columns)



